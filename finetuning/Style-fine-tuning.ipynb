{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1m_1NbHHtRqrMWgCTqlAZbI0y9Pfql4DY","authorship_tag":"ABX9TyOPWCSpKcjIVmw01Q7UQEFO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"3f15bdf9030f42fb9ba4c0b20b8113b0":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_7b1659b510e440d2a16f5c4e6232a9e6","IPY_MODEL_305fc2c3f13c44bead538026bffdbd5b","IPY_MODEL_319a2514955743988c263286cd4e4ea9"],"layout":"IPY_MODEL_42c206257ca8493a9159b23436b0d75a"}},"7b1659b510e440d2a16f5c4e6232a9e6":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4339d5719d284345a431ce113cb30660","placeholder":"​","style":"IPY_MODEL_b68a850c3c454295a40c2f6c1f90e532","value":"Map:  88%"}},"305fc2c3f13c44bead538026bffdbd5b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd0502642da34b5a9ebdd6876967451b","max":256,"min":0,"orientation":"horizontal","style":"IPY_MODEL_4d57f85b512f4dd0907a427aaa0b3a0f","value":256}},"319a2514955743988c263286cd4e4ea9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_925ad3e9879e42a7999218bb6adb99ce","placeholder":"​","style":"IPY_MODEL_f26b49a33d4c4587a9c07786c163ace2","value":" 225/256 [00:00&lt;00:00, 611.49 examples/s]"}},"42c206257ca8493a9159b23436b0d75a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"4339d5719d284345a431ce113cb30660":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b68a850c3c454295a40c2f6c1f90e532":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"fd0502642da34b5a9ebdd6876967451b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d57f85b512f4dd0907a427aaa0b3a0f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"925ad3e9879e42a7999218bb6adb99ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f26b49a33d4c4587a9c07786c163ace2":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"33f5def29d924c83803f668ae12f548a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_837a8daca9414d17975486b032ee4e14","IPY_MODEL_c0f9f8ecec6a47ed8acbeaf2a5f005f7","IPY_MODEL_308317b15a384d4299ff1e1478b9d52b"],"layout":"IPY_MODEL_0cc5055b89964ffabd90d594c4d37c0e"}},"837a8daca9414d17975486b032ee4e14":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5004e24574c44dbc8bd567e677129f94","placeholder":"​","style":"IPY_MODEL_c35728064af84a8cbc5af7725443e1f6","value":"config.json: 100%"}},"c0f9f8ecec6a47ed8acbeaf2a5f005f7":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d7d7d2d75b3c46acba6c3bb4aead7a80","max":618,"min":0,"orientation":"horizontal","style":"IPY_MODEL_6c8259d069a440c69addc2dd30814617","value":618}},"308317b15a384d4299ff1e1478b9d52b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f15d3fb985f242c8b34568c93871a155","placeholder":"​","style":"IPY_MODEL_24554d42a6294b17abe0fa960123d928","value":" 618/618 [00:00&lt;00:00, 27.5kB/s]"}},"0cc5055b89964ffabd90d594c4d37c0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5004e24574c44dbc8bd567e677129f94":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c35728064af84a8cbc5af7725443e1f6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d7d7d2d75b3c46acba6c3bb4aead7a80":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6c8259d069a440c69addc2dd30814617":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f15d3fb985f242c8b34568c93871a155":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24554d42a6294b17abe0fa960123d928":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# **Preparation**"],"metadata":{"id":"SH1pFk7mIsIX"}},{"cell_type":"code","source":["!pip install bitsandbytes==0.43.0\n","!pip install datasets==2.10.1\n","!pip install transformers==4.38.2\n","!pip install peft==0.9.0\n","!pip install sentencepiece==0.1.99\n","!pip install -U accelerate==0.28.0\n","!pip install colorama==0.4.6"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"fj8G98myLzSw","executionInfo":{"status":"ok","timestamp":1730638210007,"user_tz":-480,"elapsed":81916,"user":{"displayName":"fang jiang","userId":"00779323834154474545"}},"outputId":"5a12a3fd-82f3-47f6-ada5-27a4bd3877b5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting bitsandbytes==0.43.0\n","  Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl.metadata (1.8 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.43.0) (2.5.0+cu121)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes==0.43.0) (1.26.4)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.0) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.0) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.0) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes==0.43.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->bitsandbytes==0.43.0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes==0.43.0) (3.0.2)\n","Downloading bitsandbytes-0.43.0-py3-none-manylinux_2_24_x86_64.whl (102.2 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: bitsandbytes\n","Successfully installed bitsandbytes-0.43.0\n","Collecting datasets==2.10.1\n","  Downloading datasets-2.10.1-py3-none-any.whl.metadata (20 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1) (1.26.4)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1) (17.0.0)\n","Collecting dill<0.3.7,>=0.3.0 (from datasets==2.10.1)\n","  Downloading dill-0.3.6-py3-none-any.whl.metadata (9.8 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1) (4.66.6)\n","Collecting xxhash (from datasets==2.10.1)\n","  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n","Collecting multiprocess (from datasets==2.10.1)\n","  Downloading multiprocess-0.70.17-py310-none-any.whl.metadata (7.2 kB)\n","Requirement already satisfied: fsspec>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.11.1->datasets==2.10.1) (2024.10.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1) (3.10.10)\n","Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1) (0.24.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1) (24.1)\n","Collecting responses<0.19 (from datasets==2.10.1)\n","  Downloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.10.1) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1) (2.4.3)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1) (1.3.1)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1) (24.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1) (6.1.0)\n","Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1) (1.17.0)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.10.1) (4.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (3.16.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets==2.10.1) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.1) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.1) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.10.1) (2024.8.30)\n","INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n","Collecting multiprocess (from datasets==2.10.1)\n","  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n","  Downloading multiprocess-0.70.15-py310-none-any.whl.metadata (7.2 kB)\n","  Downloading multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.1) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.1) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.10.1) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets==2.10.1) (1.16.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets==2.10.1) (0.2.0)\n","Downloading datasets-2.10.1-py3-none-any.whl (469 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading dill-0.3.6-py3-none-any.whl (110 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: xxhash, dill, responses, multiprocess, datasets\n","Successfully installed datasets-2.10.1 dill-0.3.6 multiprocess-0.70.14 responses-0.18.0 xxhash-3.5.0\n","Collecting transformers==4.38.2\n","  Downloading transformers-4.38.2-py3-none-any.whl.metadata (130 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.7/130.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (3.16.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (0.24.7)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (24.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (2024.9.11)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (2.32.3)\n","Collecting tokenizers<0.19,>=0.14 (from transformers==4.38.2)\n","  Downloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (0.4.5)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.2) (4.66.6)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (2024.10.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.38.2) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.38.2) (2024.8.30)\n","Downloading transformers-4.38.2-py3-none-any.whl (8.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.15.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.19.1\n","    Uninstalling tokenizers-0.19.1:\n","      Successfully uninstalled tokenizers-0.19.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.44.2\n","    Uninstalling transformers-4.44.2:\n","      Successfully uninstalled transformers-4.44.2\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 3.2.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.38.2 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tokenizers-0.15.2 transformers-4.38.2\n","Collecting peft==0.9.0\n","  Downloading peft-0.9.0-py3-none-any.whl.metadata (13 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (6.0.2)\n","Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (2.5.0+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (4.38.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (4.66.6)\n","Requirement already satisfied: accelerate>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (0.34.2)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (0.4.5)\n","Requirement already satisfied: huggingface-hub>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.9.0) (0.24.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (3.16.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (2024.10.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (2.32.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.17.0->peft==0.9.0) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (3.1.4)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.9.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13.0->peft==0.9.0) (1.3.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.9.0) (2024.9.11)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.9.0) (0.15.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.9.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.17.0->peft==0.9.0) (2024.8.30)\n","Downloading peft-0.9.0-py3-none-any.whl (190 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: peft\n","  Attempting uninstall: peft\n","    Found existing installation: peft 0.13.2\n","    Uninstalling peft-0.13.2:\n","      Successfully uninstalled peft-0.13.2\n","Successfully installed peft-0.9.0\n","Collecting sentencepiece==0.1.99\n","  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n","Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: sentencepiece\n","  Attempting uninstall: sentencepiece\n","    Found existing installation: sentencepiece 0.2.0\n","    Uninstalling sentencepiece-0.2.0:\n","      Successfully uninstalled sentencepiece-0.2.0\n","Successfully installed sentencepiece-0.1.99\n","Collecting accelerate==0.28.0\n","  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0) (24.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0) (6.0.2)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0) (2.5.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0) (0.24.7)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.28.0) (0.4.5)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (3.16.1)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.28.0) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.10.0->accelerate==0.28.0) (1.3.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.28.0) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate==0.28.0) (4.66.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate==0.28.0) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.28.0) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.28.0) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.28.0) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate==0.28.0) (2024.8.30)\n","Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: accelerate\n","  Attempting uninstall: accelerate\n","    Found existing installation: accelerate 0.34.2\n","    Uninstalling accelerate-0.34.2:\n","      Successfully uninstalled accelerate-0.34.2\n","Successfully installed accelerate-0.28.0\n","Collecting colorama==0.4.6\n","  Downloading colorama-0.4.6-py2.py3-none-any.whl.metadata (17 kB)\n","Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Installing collected packages: colorama\n","Successfully installed colorama-0.4.6\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"-yOqJe0bIK2Y","executionInfo":{"status":"ok","timestamp":1730638236053,"user_tz":-480,"elapsed":26053,"user":{"displayName":"fang jiang","userId":"00779323834154474545"}}},"outputs":[],"source":["from transformers import AutoModelForCausalLM, AutoTokenizer\n","from transformers.generation import GenerationConfig\n","from transformers import BitsAndBytesConfig\n","import transformers\n","\n","from datasets import Dataset\n","import json\n","import pandas as pd\n","import torch\n","import os\n","\n","from peft import PeftModel\n","from peft import (\n","    prepare_model_for_int8_training,\n","    LoraConfig,\n","    get_peft_model\n",")\n","\n"]},{"cell_type":"code","source":["model_name=\"MediaTek-Research/Breeze-7B-Instruct-v0_1\"\n","cache_dir='/content/drive/MyDrive/Breeze'"],"metadata":{"id":"VosIaLXG6jkk","executionInfo":{"status":"ok","timestamp":1730638238697,"user_tz":-480,"elapsed":426,"user":{"displayName":"fang jiang","userId":"00779323834154474545"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["# **load the pre_trained model**\n","包括模型参数，分词器，设定解码策略"],"metadata":{"id":"ScQOaGTb6m6P"}},{"cell_type":"code","source":["# quantify\n","quantization_config = BitsAndBytesConfig(\n","    load_in_4bit=True,\n","    bnb_4bit_compute_dtype=\"float16\",\n","    bnb_4bit_quant_type=\"nf4\",\n","    bnb_4bit_use_double_quant=True,\n","    bnb_4bit_use_triton=True\n",")\n","\n","# load model parameter\n","model = AutoModelForCausalLM.from_pretrained(\n","    model_name,\n","    device_map=\"auto\",\n","    cache_dir=cache_dir,\n","    quantization_config=quantization_config\n","\n",")\n","# load tokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\n","    model_name,\n","    cache_dir=cache_dir,\n","    quantization_config=quantization_config\n",")\n","\n","# set decoding stategy\n","# random sampling\n","max_len=128\n","generation_config = GenerationConfig(\n","    max_length=max_len,\n","    do_sample=True,\n","    temperature=0.9,\n","    top_p=0.5,\n","    no_repeat_ngram_size=3,\n","    pad_token_id=2,\n",")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":707},"collapsed":true,"id":"IK7bhTsN6ygT","executionInfo":{"status":"error","timestamp":1730638257631,"user_tz":-480,"elapsed":4684,"user":{"displayName":"fang jiang","userId":"00779323834154474545"}},"outputId":"a4bf5359-08c2-4df4-f5e3-8292fb82e343"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n","The secret `HF_TOKEN` does not exist in your Colab secrets.\n","To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n","You will be able to reuse this secret in all of your notebooks.\n","Please note that authentication is recommended but still optional to access public models or datasets.\n","  warnings.warn(\n"]},{"output_type":"error","ename":"ImportError","evalue":"Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-d634dcf55f85>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# load model parameter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m model = AutoModelForCausalLM.from_pretrained(\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             return model_class.from_pretrained(\n\u001b[0m\u001b[1;32m    562\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   3022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3024\u001b[0;31m             hf_quantizer.validate_environment(\n\u001b[0m\u001b[1;32m   3025\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_flax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_flax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3026\u001b[0m             )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_bitsandbytes_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m             raise ImportError(\n\u001b[0m\u001b[1;32m     63\u001b[0m                 \u001b[0;34m\"Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0;34m\"and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mImportError\u001b[0m: Using `bitsandbytes` 8-bit quantization requires Accelerate: `pip install accelerate` and the latest version of bitsandbytes: `pip install -i https://pypi.org/simple/ bitsandbytes`","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}]},{"cell_type":"code","source":["instruction=\"我会给你一首诗的前两句，然后你续写两句\"\n","input=\"窗前明月光，疑是地上霜\"\n","prompt=\"\"\"\n","[INST] <<SYS>>\n","You are a helpful assistant and good at writing Tang poem.\n","<</SYS>>\n","{instruction}\n","{input}\n","[/INST]\n","\"\"\"\n","input_text=prompt.format(instruction=instruction,input=input)\n","input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.cuda()\n","print(input_ids)\n","print(\"-\"*20)\n","response=model.generate(\n","    input_ids=input_ids,\n","    max_length=max_len,\n","    do_sample=generation_config.do_sample,\n","    temperature=generation_config.temperature,\n","    num_beams=generation_config.num_beams,\n","    top_p=generation_config.top_p,\n","    no_repeat_ngram_size=generation_config.no_repeat_ngram_size,\n","    pad_token_id=generation_config.pad_token_id\n",")\n","print(response)\n","print(\"-\"*20)\n","# 解码生成的输出\n","generated_text = tokenizer.decode(response[0], skip_special_tokens=True)\n","\n","# 打印生成的文本\n","print(generated_text)\n","print(\"-\"*20)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"za2skbBTJxau","executionInfo":{"status":"ok","timestamp":1724050294423,"user_tz":-480,"elapsed":22889,"user":{"displayName":"fang jiang","userId":"00779323834154474545"}},"outputId":"dcdd9411-91d8-4215-c208-e2f76f593dd4","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[    1, 28705,    13, 28792, 16289, 28793,  2087, 18741,  4060,    13,\n","          1976,   460,   264, 10865, 13892,   304,  1179,   438,  3653,   320,\n","           602, 16067, 28723,    13, 28789,   700, 18741,  4060,    13, 29242,\n","         29179, 29709, 29383, 47223,   235,   178,   154, 28914, 29087, 29745,\n","         30347, 28924, 51540, 29383, 30199, 29503, 29745, 30347,    13, 30171,\n","         29087, 29381, 49533, 28924, 33982, 28971, 45312, 35525,    13, 28792,\n","         28748, 16289, 28793,    13]], device='cuda:0')\n","--------------------\n"]},{"output_type":"stream","name":"stderr","text":["The attention mask is not set and cannot be inferred from input because pad token is same as eos token.As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"]},{"output_type":"stream","name":"stdout","text":["tensor([[    1, 28705,    13, 28792, 16289, 28793,  2087, 18741,  4060,    13,\n","          1976,   460,   264, 10865, 13892,   304,  1179,   438,  3653,   320,\n","           602, 16067, 28723,    13, 28789,   700, 18741,  4060,    13, 29242,\n","         29179, 29709, 29383, 47223,   235,   178,   154, 28914, 29087, 29745,\n","         30347, 28924, 51540, 29383, 30199, 29503, 29745, 30347,    13, 30171,\n","         29087, 29381, 49533, 28924, 33982, 28971, 45312, 35525,    13, 28792,\n","         28748, 16289, 28793,    13, 30171,   233,   170,   158, 29376, 29395,\n","           233,   184,   136, 28924, 29783, 29065, 30370, 29870, 31835, 29085,\n","           236,   181,   159,     2]], device='cuda:0')\n","--------------------\n","\n","[INST] <<SYS>>\n","You are a helpful assistant and good at writing Tang poem.\n","<</SYS>>\n","我会给你一首诗的前两句，然后你续写两句\n","窗前明月光，疑是地上霜\n","[/INST]\n","窗槛月色浅，步出院门冰点鲜\n","--------------------\n"]}]},{"cell_type":"markdown","source":["# finetuning\n","使用唐诗数据集https://github.com/CheeEn-Yu/GenAI-Hw5"],"metadata":{"id":"nL9aZZMAY_UQ"}},{"cell_type":"markdown","metadata":{"id":"ESzwsaT9poC4"},"source":["## Fix Random Seeds\n","There may be some randomness involved in the fine-tuning process. We fix random seeds to make the result reproducible."]},{"cell_type":"code","source":["seed = 42\n","torch.backends.cudnn.deterministic = True\n","torch.backends.cudnn.benchmark = False\n","torch.manual_seed(seed)\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)"],"metadata":{"id":"ll4MpzGCoHmL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## load datasets"],"metadata":{"id":"oHqhrFT1BsHX"}},{"cell_type":"code","source":["cd /content/drive/MyDrive"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"l8pyIrTKaHq9","executionInfo":{"status":"ok","timestamp":1724050343721,"user_tz":-480,"elapsed":394,"user":{"displayName":"fang jiang","userId":"00779323834154474545"}},"outputId":"51b105b4-db06-459a-aeab-e5a992fbc579"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive\n"]}]},{"cell_type":"code","source":["!git clone https://github.com/CheeEn-Yu/GenAI-Hw5"],"metadata":{"id":"_ZZlnLNCZfTW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1724050351572,"user_tz":-480,"elapsed":2611,"user":{"displayName":"fang jiang","userId":"00779323834154474545"}},"outputId":"55313999-e166-4e45-81f9-dec2ac7f7f8e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'GenAI-Hw5'...\n","remote: Enumerating objects: 38, done.\u001b[K\n","remote: Counting objects: 100% (38/38), done.\u001b[K\n","remote: Compressing objects: 100% (29/29), done.\u001b[K\n","remote: Total 38 (delta 15), reused 26 (delta 7), pack-reused 0 (from 0)\u001b[K\n","Receiving objects: 100% (38/38), 3.68 MiB | 6.33 MiB/s, done.\n","Resolving deltas: 100% (15/15), done.\n"]}]},{"cell_type":"code","source":["def generate_training_data(data_point):\n","    \"\"\"\n","    (1) Goal:\n","        - This function is used to transform a data point (input and output texts) to tokens that our model can read\n","\n","    (2) Arguments:\n","        - data_point: dict, with field \"instruction\", \"input\", and \"output\" which are all str\n","\n","    (3) Returns:\n","        - a dict with model's input tokens, attention mask that make our model causal, and corresponding output targets\n","\n","    (3) Example:\n","        - If you construct a dict, data_point_1, with field \"instruction\", \"input\", and \"output\" which are all str, you can use the function like this:\n","            formulate_article(data_point_1)\n","\n","    \"\"\"\n","    # construct full input prompt\n","    prompt = f\"\"\"\\\n","[INST] <<SYS>>\n","You are a helpful assistant and good at writing Tang poem. 你是一個樂於助人的助手且擅長寫唐詩。\n","<</SYS>>\n","\n","{data_point[\"instruction\"]}\n","{data_point[\"input\"]}\n","[/INST]\"\"\"\n","    # count the number of input tokens\n","    len_user_prompt_tokens = (\n","        len(\n","            tokenizer(\n","                prompt,\n","                truncation=True,\n","                max_length=CUTOFF_LEN + 1,\n","                padding=\"max_length\",\n","            )[\"input_ids\"]\n","        ) - 1\n","    )\n","    # transform input prompt into tokens\n","    full_tokens = tokenizer(\n","        prompt + \" \" + data_point[\"output\"] + \"</s>\",\n","        truncation=True,\n","        max_length=CUTOFF_LEN + 1,\n","        padding=\"max_length\",\n","    )[\"input_ids\"][:-1]\n","    return {\n","        \"input_ids\": full_tokens,\n","        \"labels\": [-100] * len_user_prompt_tokens\n","        + full_tokens[len_user_prompt_tokens:],\n","        \"attention_mask\": [1] * (len(full_tokens)),\n","    }"],"metadata":{"id":"qCqiURfrkyS8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CUTOFF_LEN = 256  # 設定文本截斷的最大長度\n","data_file='/content/drive/MyDrive/GenAI-Hw5/Tang_training_data.json'\n","with open(data_file,'r',encoding='utf-8') as f:\n","  data_json=json.load(f)\n","data = Dataset.from_pandas(pd.DataFrame(data_json[:256]))\n","train_data=data.shuffle().map(generate_training_data)"],"metadata":{"id":"Gq9K1x4NZlYT","colab":{"base_uri":"https://localhost:8080/","height":17,"referenced_widgets":["3f15bdf9030f42fb9ba4c0b20b8113b0","7b1659b510e440d2a16f5c4e6232a9e6","305fc2c3f13c44bead538026bffdbd5b","319a2514955743988c263286cd4e4ea9","42c206257ca8493a9159b23436b0d75a","4339d5719d284345a431ce113cb30660","b68a850c3c454295a40c2f6c1f90e532","fd0502642da34b5a9ebdd6876967451b","4d57f85b512f4dd0907a427aaa0b3a0f","925ad3e9879e42a7999218bb6adb99ce","f26b49a33d4c4587a9c07786c163ace2"]},"executionInfo":{"status":"ok","timestamp":1724156429469,"user_tz":-480,"elapsed":1386,"user":{"displayName":"fang jiang","userId":"00779323834154474545"}},"outputId":"ce4126cf-a5b4-430b-b33e-4757dd5e91d3"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/256 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f15bdf9030f42fb9ba4c0b20b8113b0"}},"metadata":{}}]},{"cell_type":"markdown","source":["## finetune model"],"metadata":{"id":"-7LoFD6iB1jL"}},{"cell_type":"code","source":["check=False\n","checkpoint=os.path.join(cache_dir,'exp')\n","logging_steps = 20  # 定義訓練過程中每隔多少步驟輸出一次訓練誌\n","save_steps = 65  # 定義訓練過程中每隔多少步驟保存一次模型\n","save_total_limit = 3  # 控制最多保留幾個模型checkpoint\n","report_to = None  # 設定上報實驗指標的目標，預設為無\n","num_epoch=1\n","LEARNING_RATE=3e-4\n","MICRO_BATCH_SIZE = 4  # 定義微批次的大小\n","BATCH_SIZE = 16  # 定義一個批次的大小\n","GRADIENT_ACCUMULATION_STEPS = BATCH_SIZE // MICRO_BATCH_SIZE  # 計算每個微批次累積的梯度步數\n","CUTOFF_LEN = 256  # 設定文本截斷的最大長度\n","LORA_R = 8  # 設定LORA（Layer-wise Random Attention）的R值\n","LORA_ALPHA = 16  # 設定LORA的Alpha值\n","LORA_DROPOUT = 0.05  # 設定LORA的Dropout率\n","VAL_SET_SIZE = 0  # 設定驗證集的大小，預設為無\n","TARGET_MODULES = [\"q_proj\", \"up_proj\", \"o_proj\", \"k_proj\", \"down_proj\", \"gate_proj\", \"v_proj\"] # 設定目標模組，這些模組的權重將被保存為checkpoint\n","device_map = \"auto\"  # 設定設備映射，預設為\"auto\"\n","world_size = int(os.environ.get(\"WORLD_SIZE\", 1))  # 獲取環境變數\"WORLD_SIZE\"的值，若未設定則預設為1\n","ddp = world_size != 1  # 根據world_size判斷是否使用分散式數據處理(DDP)，若world_size為1則不使用DDP\n","if ddp:\n","    device_map = {\"\": int(os.environ.get(\"LOCAL_RANK\") or 0)}\n","    GRADIENT_ACCUMULATION_STEPS = GRADIENT_ACCUMULATION_STEPS // world_size"],"metadata":{"id":"9YsIGGZ7OZrz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# load model from checkpoint\n","if check:\n","  model=PeftModel.from_pretrained(model,checkpoint)\n","\n","# int8 training model\n","model=prepare_model_for_int8_training(model)\n","\n","# lora training model\n","lora_config = LoraConfig(\n","    r=LORA_R,\n","    lora_alpha=LORA_ALPHA,\n","    target_modules=TARGET_MODULES,\n","    lora_dropout=LORA_DROPOUT,\n","    bias=\"none\",\n","    task_type=\"CAUSAL_LM\",\n",")\n","model=get_peft_model(model,lora_config)\n","# 如果加载不成功，可能是包版本问题\n","trainer = transformers.Trainer(\n","    model=model,\n","    train_dataset=train_data,\n","    eval_dataset=None,\n","    args=transformers.TrainingArguments(\n","        per_device_train_batch_size=MICRO_BATCH_SIZE,\n","        gradient_accumulation_steps=GRADIENT_ACCUMULATION_STEPS,\n","        warmup_steps=50,\n","        num_train_epochs=num_epoch,\n","        learning_rate=LEARNING_RATE,\n","        fp16=True,  # 使用混合精度訓練\n","        logging_steps=logging_steps,\n","        save_strategy=\"steps\",\n","        save_steps=save_steps,\n","        output_dir=checkpoint,\n","        save_total_limit=save_total_limit,\n","        ddp_find_unused_parameters=False if ddp else None,  # 是否使用 DDP，控制梯度更新策略\n","        report_to=report_to,\n","    ),\n","    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",")\n","trainer.train()\n","os.makedirs(checkpoint, exist_ok = True)\n","model.save_pretrained(checkpoint)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":288,"referenced_widgets":["33f5def29d924c83803f668ae12f548a","837a8daca9414d17975486b032ee4e14","c0f9f8ecec6a47ed8acbeaf2a5f005f7","308317b15a384d4299ff1e1478b9d52b","0cc5055b89964ffabd90d594c4d37c0e","5004e24574c44dbc8bd567e677129f94","c35728064af84a8cbc5af7725443e1f6","d7d7d2d75b3c46acba6c3bb4aead7a80","6c8259d069a440c69addc2dd30814617","f15d3fb985f242c8b34568c93871a155","24554d42a6294b17abe0fa960123d928"]},"id":"ISGrBXQxCU4U","executionInfo":{"status":"ok","timestamp":1724156762125,"user_tz":-480,"elapsed":299845,"user":{"displayName":"fang jiang","userId":"00779323834154474545"}},"outputId":"015a88c2-c272-4e3b-c50f-10973d023f97"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:145: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:432: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n","dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='16' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [16/16 04:27, Epoch 1/1]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Step</th>\n","      <th>Training Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"output_type":"display_data","data":{"text/plain":["config.json:   0%|          | 0.00/618 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"33f5def29d924c83803f668ae12f548a"}},"metadata":{}}]},{"cell_type":"markdown","source":["# test finetuning model"],"metadata":{"id":"xlL1OHK_v-nb"}},{"cell_type":"code","source":["# find all available checkpoints\n","ckpts = []\n","for ckpt in os.listdir(checkpoint):\n","    if (ckpt.startswith(\"checkpoint-\")):\n","        ckpts.append(ckpt)\n","\n","# list all the checkpoints\n","ckpts = sorted(ckpts, key = lambda ckpt: int(ckpt.split(\"-\")[-1]))\n","print(\"all available checkpoints:\")\n","print(\" id: checkpoint name\")\n","for (i, ckpt) in enumerate(ckpts):\n","    print(f\"{i:>3}: {ckpt}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YhGlPZFcxZiX","executionInfo":{"status":"ok","timestamp":1724157124747,"user_tz":-480,"elapsed":601,"user":{"displayName":"fang jiang","userId":"00779323834154474545"}},"outputId":"84ab1018-5e83-45af-8792-3931540269ec"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["all available checkpoints:\n"," id: checkpoint name\n"]}]},{"cell_type":"code","source":["model = PeftModel.from_pretrained(model, checkname, device_map={'': 0})"],"metadata":{"id":"x0b0Hx6bwDVR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["CUTOFF_LEN = 256  # 設定文本截斷的最大長度\n","data_file='/content/drive/MyDrive/GenAI-Hw5/Tang_testing_data.json'\n","with open(data_file,'r',encoding='utf-8') as f:\n","  test_datas=json.load(f)\n","\n","\n","prompt=\"\"\"\n","[INST] <<SYS>>\n","You are a helpful assistant and good at writing Tang poem.\n","<</SYS>>\n","{instruction}\n","{input}\n","[/INST]\n","\"\"\"\n","\n","for (i,test_data) in enumerate(test_datas):\n","\n","  input_text=prompt.format(instruction=test_data['instruction'],input=test_data['input'])\n","  input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.cuda()\n","\n","  response=model.generate(\n","      input_ids=input_ids,\n","      max_length=max_len,\n","      do_sample=generation_config.do_sample,\n","      temperature=generation_config.temperature,\n","      num_beams=generation_config.num_beams,\n","      top_p=generation_config.top_p,\n","      no_repeat_ngram_size=generation_config.no_repeat_ngram_size,\n","      pad_token_id=generation_config.pad_token_id\n","  )\n","\n","  # 解码生成的输出\n","  generated_text = tokenizer.decode(response[0], skip_special_tokens=True)\n","\n","  # 打印生成的文本\n","  print(i,generated_text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZF-X5JNBx2nY","outputId":"42136a28-b54f-469c-cd2e-4b9ba86f9d79"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:91: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["0 \n","[INST] <<SYS>>\n","You are a helpful assistant and good at writing Tang poem.\n","<</SYS>>\n","以下是一首唐詩的第一句話，請用你的知識判斷並完成整首詩。\n","雪霽銀妝素，桔高映瓊枝。\n","[/INST]\n","[Inst] 玉堂一簾簾，金簾一簾開。\n","\n","[SYS] 紫雲輕掩下，金光微映邊。\n","鳳冠鳳冠出，鳳裳鳳裳回。\n","一窗一窗明，一窗以一開。\n","1 \n","[INST] <<SYS>>\n","You are a helpful assistant and good at writing Tang poem.\n","<</SYS>>\n","以下是一首唐詩的第一句話，請用你的知識判斷並完成整首詩。\n","夫子何爲者？栖栖一代中。\n","[/INST]\n","道心自無惑，而物亦何如。\n","自能不以物，而能以心。\n","心之所以定，乃在無欲之。\n","無欲則無欲，無欲是無欲。\n","欲之所欲求，欲之所以求\n","2 \n","[INST] <<SYS>>\n","You are a helpful assistant and good at writing Tang poem.\n","<</SYS>>\n","以下是一首唐詩的第一句話，請用你的知識判斷並完成整首詩。\n","飛蓋去芳園，蘭橈遊翠渚。\n","[/INST]\n","一池碧色水，百枝紅姿華。玉香散風中，金露滴日下。欲見雙鳳姿，欲聞雙鳳歌。誰家有此園，莫待百花花。\n","</SYS>\n"]}]}]}